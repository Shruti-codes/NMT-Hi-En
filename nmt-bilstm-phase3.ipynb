{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"CUDA_LAUNCH_BLOCKING=\"1\"","metadata":{"id":"ZsLsDJUDvtct","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\"","metadata":{"id":"0nq5-nsZ0q6j","outputId":"e9663ebb-27b9-4fb9-9612-6f42014eff52","trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git","metadata":{"id":"KxX3o65b0sCr","outputId":"47881810-7f7e-492b-8651-334b7a2c2f88","trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install indic-nlp-library","metadata":{"id":"LF9MRsrn0u2Z","outputId":"c84e3b88-fff4-4e1f-a131-f7ff185caf0d","trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting indic-nlp-library\n  Downloading indic_nlp_library-0.71-py3-none-any.whl (38 kB)\nCollecting morfessor\n  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from indic-nlp-library) (1.1.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from indic-nlp-library) (1.19.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->indic-nlp-library) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->indic-nlp-library) (2021.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\nInstalling collected packages: morfessor, indic-nlp-library\nSuccessfully installed indic-nlp-library-0.71 morfessor-2.0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount(\"/content/gdrive\")\n# import os\n# import sys\n# path = '/content/gdrive/My Drive/'\n# os.chdir(path)\n# print(os.getcwd())","metadata":{"id":"P7DLw2Ri0zdu","outputId":"f59e0845-d1ba-4f8f-ad2a-631b8a428ff2","trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!head train2.csv","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"head: cannot open 'train2.csv' for reading: No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"#loading libraries\nimport torch\ntorch.cuda.empty_cache()\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.utils import data\nimport torch.nn.functional as F\nprint(torch.__version__)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nimport string\nimport re\nimport random\nfrom nltk.tokenize import word_tokenize\nfrom unicodedata import normalize\nimport numpy as np\nfrom numpy import array","metadata":{"id":"2J1N_pmXvtcv","outputId":"cbb1679b-f909-4504-d44a-3e2d4df334f1","trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1.7.0\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from indicnlp.tokenize import indic_tokenize ","metadata":{"id":"uNrNQ5Mtvtcx","trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# from indicnlp.normalize.indic_normalize import DevanagariNormalizer\n# factory = DevanagariNormalizer()\n\nfrom indicnlp.normalize.indic_normalize import IndicNormalizerFactory\nfactory=IndicNormalizerFactory()\nnormalizer=factory.get_normalizer(\"hi\",remove_nuktas=False)","metadata":{"id":"7PTDWdEmvtcy","trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Data Cleaning","metadata":{}},{"cell_type":"code","source":"#Lowercase, trim, and remove non-letter characters\ndef normalizeString(w):\n  #insert space between words and punctuations\n  w = re.sub(r\"([?.!,¿-])\", r\" \\1 \", w)\n  w = re.sub(r\"[().!,?-]+\", r\" \", w)\n  w = re.sub(r'[\" \"]+', \" \", w) #multiple spaces\n  w = w.lower().strip() #lowercase #Remove white spaces\n  return w","metadata":{"id":"VrOg-NdLvtc1","trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"id":"2bo5V57L1Amj","outputId":"3197d90e-cd42-4b95-f3e8-6f4840c28704","trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"abbr = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'll\": \"he will\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'll\": \"how will\",\n\"how's\": \"how is\",\n\"here's\": \"here is\",\n\"i'd\": \"i would\",\n\"i'll\": \"i will\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'll\": \"it will\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"needn't\": \"need not\",\n\"she'd\": \"she would\",\n\"she'll\": \"she will\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"that'd\": \"that would\",\n\"that's\": \"that is\",\n\"there'd\": \"there had\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'll\": \"they will\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we would\",\n\"we'll\": \"we will\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what will\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"where'd\": \"where did\",\n\"where's\": \"where is\",\n\"who'll\": \"who will\",\n\"who's\": \"who is\",\n\"won't\": \"will not\",\n\"wouldn't\": \"would not\",\n\"you'd\": \"you would\",\n\"you'll\": \"you will\",\n\"you're\": \"you are\",\n\"y'all\":\"you all\",\n\"let's\": \"let us\"\n}","metadata":{"id":"kT-V6iqbvtcz","trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import csv\ndata = []\nwith open('/kaggle/input/traincsv/train.csv') as csvfile:\n    csvReader = csv.reader(csvfile, delimiter=',')\n    for row in csvReader:\n        data.append([normalizeString(row[1]), normalizeString(row[2])])","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for l in data:\n  for w in l[1].split():\n    if(w in abbr.keys()):\n      #print(w)\n      l[1] = l[1].replace(w, abbr[w])\n      break","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data = data[1:]","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test = []\nwith open('/kaggle/input/testhindi/testhindistatements.csv') as csvfile:\n    csvReader = csv.reader(csvfile, delimiter=',')\n    for row in csvReader:\n        test.append([row[2]])","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#start of sentence\nSOS_token = 0\n#end of sentence\nEOS_token = 1\n\n#helper class - converting textual data to numeric form, creating vocabulary\nclass Lang:\n  def __init__(self, name):\n    self.name = name\n    #word -> index\n    self.word2index = {\"SOS\" : 0, \"EOS\" : 1, \"UNK\" : 2}\n    #count of each word to later replace rare words\n    self.word2count = {}\n    #index -> word\n    self.index2word = {0: \"SOS\", 1: \"EOS\", 2 : \"UNK\"}\n    self.n_words = 3  # Count SOS, EOS, UNK tokens\n\n  def addSentence(self, sentence):\n    sentence_split = sentence.split(' ')\n    for word in sentence.split(' '):\n      self.addWord(word)\n\n  def addWord(self, word):\n    if word not in self.word2index:\n      # word to index mapping\n      self.word2index[word] = self.n_words\n      self.word2count[word] = 1\n      self.index2word[self.n_words] = word\n      self.n_words += 1\n    else:\n      self.word2count[word] += 1","metadata":{"id":"zX3oX2EAvtcy","trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test = test[1:]","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def clean_pairs(lines):\n  cleaned = list()\n  regex = re.compile('[%s]' % re.escape(string.punctuation))\n\n  for pair in lines:\n    clean_pair = list()\n    \n    #cleaning hindi phrases\n    line = pair[0]\n    line = normalizer.normalize(line)\n    tokens = list()\n    for t in indic_tokenize.trivial_tokenize(line): \n        tokens.append(t)\n    line = tokens\n    line = [word for word in line if not re.search(r'\\d', word)]\n    line = [regex.sub('', w) for w in line]\n    #Replace the english characters\n    line = [re.sub(r\"[a-zA-Z]+?\\s\", \"\", w) for w in line]\n    line = [re.sub(r'[-.।|,?;:<>&$₹]+','',w) for w in line]\n    clean_pair.append(' '.join(line))\n\n    #cleaning english phrases\n    line = pair[1]\n    #convert unicode line to plain ascii\n    line = normalize('NFD', line).encode('ascii', 'ignore')\n    line = line.decode('UTF-8')\n    line = word_tokenize(line) \n    line = [regex.sub('', w) for w in line]\n    #replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n    line = [re.sub(r\"[^a-zA-Z0-9?.!,¿\\-\\/]+\", \" \", w) for w in line]\n    line = [re.sub(r\" - \", \"-\", w) for w in line]\n    line = [word for word in line if word.isalpha()]\n    clean_pair.append(' '.join(line))\n    \n    cleaned.append(clean_pair)\n  return array(cleaned)","metadata":{"id":"34lHypu8vtc1","trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Filtering sentences that are too long","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 60\n\ndef filterPair(p):\n    return len(p[0].split(' ')) <= MAX_LENGTH and len(p[1].split(' ')) <= MAX_LENGTH\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","metadata":{"id":"Rfh9x7iXvtc3","trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def prepareData(lang1, lang2):\n    #make Lang instances\n    input_lang = Lang(lang1)\n    output_lang = Lang(lang2)\n    print(\"Read %s sentence pairs\" % len(data))\n    pairs = clean_pairs(data)\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    #Make word lists from sentences in pairs\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Input Language\\tTrimmed Vocabulary Size\")\n    print(input_lang.name, input_lang.n_words)\n    print(\"Output Language\\tTrimmed Vocabulary Size\")\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs, test","metadata":{"id":"1qyHAVqsvtc4","trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"input_lang, output_lang, tr_pairs, pairst = prepareData('hindi', 'english')\nprint(random.choice(tr_pairs))","metadata":{"id":"i-Zrvhffvtc4","outputId":"bb489ab5-06a2-4fe2-c1a1-c2dd845204e1","trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Read 101322 sentence pairs\nTrimmed to 100926 sentence pairs\nInput Language\tTrimmed Vocabulary Size\nhindi 43447\nOutput Language\tTrimmed Vocabulary Size\nenglish 29399\n['अब क्या करें' 'what do we do']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(random.choice(tr_pairs))\nfrom sklearn.model_selection import train_test_split\n \n#split data into train and test set\n#pairs, val_pairs = train_test_split(tr_pairs, test_size=0.1, random_state = 12)","metadata":{"id":"vowo1wQCvtc5","outputId":"697c0dff-ccaa-4a40-9587-75961fe46bee","trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"['और जीवित ग्रंथों के अनुवाद का कहना है मैं इसका इलाज नहीं करूँगा इसका मै इलाज नहीं कर सकता'\n 'and the translations of the surviving texts say this i will not treat this i can not treat']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(tr_pairs))\nprint(len(pairst))","metadata":{"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"100926\n24102\n","output_type":"stream"}]},{"cell_type":"code","source":"#vectorize sentences - using unique index for the word rather than entire one hot vector for each word\ndef indexesFromSentence(lang, sentence):\n    indexes = []\n    for word in sentence.split(' '):\n        try:\n            indexes.append(lang.word2index[word])\n        except:\n            indexes.append(lang.word2index[\"UNK\"])\n    return indexes\n\n#one hot vector representation\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    result = torch.LongTensor(indexes).view(-1).cuda()\n    return result\n\n#convert pair of sentence to pair of tensors\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","metadata":{"id":"JSt4r9Egvtc6","trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#make batches of data\ndef batchify(data, batch_size):\n    shuffle(data)\n\n    num_of_batches = len(data) // batch_size\n    batches = list(range(num_of_batches))\n\n    for batch_num in range(num_of_batches):\n        input_tensor = list(range(batch_size))\n        target_tensor = list(range(batch_size))\n        index = 0  \n\n        for pair in range((batch_num*batch_size),((batch_num+1)*batch_size)):\n            input_tensor[index], target_tensor[index] = tensorsFromPair(data[pair])\n            index += 1\n\n        batches[batch_num] = (input_tensor, target_tensor)\n\n    return batches\n \n#append EOS tag to end of shorter sentences so that all in batch are same length\ndef pad_batch(batch):\n    padded_inputs = torch.nn.utils.rnn.pad_sequence(batch[0],padding_value=EOS_token)\n    padded_targets = torch.nn.utils.rnn.pad_sequence(batch[1],padding_value=EOS_token)\n    return (padded_inputs, padded_targets)","metadata":{"id":"Qh33xiCovtc8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self,input_size,hidden_size,layers=1,dropout_p=0.1, bidirectional=True):\n        super(EncoderRNN, self).__init__()\n        #Model parameters\n        self.directions = 2 if bidirectional else 1\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.n_layers = layers\n        self.dropout_p = dropout_p if self.n_layers > 1 else 0\n        self.bidirectional = bidirectional\n        \n        #Construct the layers\n        self.embed = nn.Embedding(self.input_size,self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.lstm = nn.LSTM(input_size=self.hidden_size,hidden_size=self.hidden_size,\n                            num_layers=self.n_layers,dropout=self.dropout_p,bidirectional=self.bidirectional,\n                            batch_first=False)\n        self.fc = nn.Linear(self.hidden_size*self.directions, self.hidden_size)\n\n    def forward(self, input, h_hidden, c_hidden):\n        embedded = self.embed(input)\n        embedded = self.dropout(embedded)\n        #embedded tensor into RNN layer - (batchsize, maxlength,2*hidden)\n        hiddens, outputs = self.lstm(embedded, (h_hidden, c_hidden))\n        return hiddens, outputs\n\n    def initHidden(self, batch_size):\n        #for first time step, hidden state is empty vector\n        h_hidden = Variable(torch.zeros(self.n_layers*self.directions,batch_size, self.hidden_size, device=device))\n        c_hidden = Variable(torch.zeros(self.n_layers*self.directions,batch_size, self.hidden_size, device=device))\n        return h_hidden, c_hidden","metadata":{"id":"x3_CkvHyvtc8","trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class DecoderAttn(nn.Module):\n    def __init__(self, hidden_size, output_size, layers=1, dropout_p=0.1, bidirectional=True):\n        super(DecoderAttn, self).__init__()\n        #Model parameters\n        self.directions = 2 if bidirectional else 1\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.n_layers = layers\n        self.dropout_p = dropout_p if self.n_layers > 1 else 0 \n        self.bidirectional = bidirectional\n        \n        #construct layers\n        self.embed = nn.Embedding(self.output_size,self.hidden_size)\n        self.dropout = nn.Dropout(dropout_p)\n        #Construct layer that calculates attentional weights\n        self.score_learner = nn.Linear(self.hidden_size*self.directions, self.hidden_size*self.directions)\n        self.lstm = nn.LSTM(input_size=self.hidden_size,hidden_size=self.hidden_size,\n                            num_layers=self.n_layers,dropout=self.dropout_p, bidirectional=self.bidirectional,\n                            batch_first=False)\n        #Construct layer that compresses the combined matrix of the input embeddings and the encoder inputs after attention has been applied\n        self.context_combiner = nn.Linear((hidden_size*self.directions)+(hidden_size*self.directions), hidden_size)\n        self.tanh = nn.Tanh()\n        #Output fc layer - to determine weights\n        #1 weight per word in seq so dim = hiddensize*outputvocab\n        self.output = nn.Linear(self.hidden_size, self.output_size)\n        #weights should sum to 1\n        self.soft = nn.Softmax(dim=1)\n        self.log_soft = nn.LogSoftmax(dim=1)\n\n\n    def forward(self, input_data, h_hidden, c_hidden, encoder_hiddens):\n        #Input word indices, should have dim(1, batch_size), output will be (1, batch_size, embedding_dim)\n        embedded = self.embed(input_data)\n        embedded = self.dropout(embedded)\n        batch_size = embedded.shape[1]\n        hiddens, outputs = self.lstm(embedded, (h_hidden, c_hidden))\n        #To determine weights,concatenation of the previous hidden state of the Decoder & embedded decoder output from prev step\n        top_hidden = outputs[0].view(self.n_layers,self.directions,hiddens.shape[1],self.hidden_size)[self.n_layers-1]\n        top_hidden = top_hidden.permute(1,2,0).contiguous().view(batch_size,-1, 1)\n        #dim = (batchsize, hidden+embedding size)\n        prep_scores = self.score_learner(encoder_hiddens.permute(1,0,2))\n        #compute attention scores (weights) - global attention\n        scores = torch.bmm(prep_scores, top_hidden)\n        #get attention distribution; dim = (batchsize,seqlength)\n        attn_scores = self.soft(scores)\n        #weighted sum of encoder states - apply attention weights; Remove extra dimension, dim = (batch_size, 2*encoder_hidden_size)\n        con_mat = torch.bmm(encoder_hiddens.permute(1,2,0),attn_scores)\n        #fc+tanh\n        h_tilde = self.tanh(self.context_combiner(torch.cat((con_mat,top_hidden),dim=1).view(batch_size,-1)))\n        #pred for next word in seq\n        pred = self.output(h_tilde)\n        #A dense softmax layer to generate prob dist. over the target vocabulary\n        pred = self.log_soft(pred)\n\n        return pred, outputs","metadata":{"id":"L8XqDoDvvtc9","trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"clip = 5.0\nteacher_forcing_ratio = 0.5","metadata":{"id":"5utt4yKYvtc-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training batch-wise\ndef train(train_batches, encoder, decoder, encoder_optimizer, decoder_optimizer,criterion):\n    losses = 0\n    #completing forward pass for each sentence in batch\n    for batch in train_batches:\n        (input_batch, target_batch) = pad_batch(batch)\n        #print(input_batch.shape)\n        #clear the gradients in the optimizers\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n        loss = 0\n        #Initialize encoder hidden state\n        enc_h_hidden, enc_c_hidden = encoder.initHidden(input_batch.shape[1])\n        #meaning of whole sentence in hidden vector - context vector\n        #run forward pass through encoder on entire sequence - in parallel for each sentence in batch\n        enc_hiddens, enc_outputs = encoder(input_batch, enc_h_hidden, enc_c_hidden)\n\n        #give SOS as input for first time step\n        decoder_input = Variable(torch.LongTensor(1,input_batch.shape[1]).fill_(output_lang.word2index.get(\"SOS\")).cuda())\n        #Below tensors will hold the states of the previous time step\n        dec_h_hidden = enc_outputs[0]\n        dec_c_hidden = enc_outputs[1]\n\n        #using the \"Teacher forcing\" - passing the actual output sentence as the input to decoder\n#         if(random.random() < teacher_forcing_ratio):\n#             use_teacher_forcing = True\n#         else:\n#             use_teacher_forcing = False\n        \n        use_teacher_forcing = True\n        \n        #Step through target sequence\n        if use_teacher_forcing:\n            for i in range(target_batch.shape[0]):\n                #Forward pass through decoder - encoder outputs and predicted word index from previous time\n                pred, dec_outputs = decoder(decoder_input, dec_h_hidden, dec_c_hidden, enc_hiddens)\n                #Feed target as input to next item in the sequence\n                decoder_input = target_batch[i].view(1,-1)\n                dec_h_hidden = dec_outputs[0]\n                dec_c_hidden = dec_outputs[1]\n\n                loss += criterion(pred,target_batch[i])\n        else:\n            for i in range(target_batch.shape[0]):\n                pred, dec_outputs = decoder(decoder_input, dec_h_hidden, dec_c_hidden, enc_hiddens)\n                #word with max prob becomes predicted word\n                topv, topi = pred.topk(1,dim=1)\n                ni = topi.view(1,-1)\n                #using predicted word as input to next time-step\n                decoder_input = ni\n                dec_h_hidden = dec_outputs[0]\n                dec_c_hidden = dec_outputs[1]\n                #computing accuracy of predicted translation to actual translation. summing over the loss for each word\n                loss += criterion(pred,target_batch[i])        \n\n        #backpropagate the loss\n        loss.backward()\n        #Clip the gradients\n        torch.nn.utils.clip_grad_norm_(encoder.parameters(),clip)\n        torch.nn.utils.clip_grad_norm_(decoder.parameters(),clip)\n        #updated weights slightly enhance accuracy\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n        #summing over loss of several sentences in batch\n        batch_loss = loss.item() / target_batch.shape[0]\n        losses += batch_loss\n\n    return losses / len(train_batches)","metadata":{"id":"E5G1972uvtc-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(test_batches, encoder, decoder, criterion):\n    with torch.no_grad():\n        losses = 0\n        for batch in test_batches:\n            (input_batch, target_batch) = pad_batch(batch)\n\n            loss = 0\n            enc_h_hidden, enc_c_hidden = encoder.initHidden(input_batch.shape[1])\n            enc_hiddens, enc_outputs = encoder(input_batch, enc_h_hidden, enc_c_hidden)\n\n            decoder_input = Variable(torch.LongTensor(1,input_batch.shape[1]).fill_(output_lang.word2index.get(\"SOS\")).cuda())\n            dec_h_hidden = enc_outputs[0]\n            dec_c_hidden = enc_outputs[1]\n\n            for i in range(target_batch.shape[0]):\n                pred, dec_outputs = decoder(decoder_input, dec_h_hidden, dec_c_hidden, enc_hiddens)\n                topv, topi = pred.topk(1,dim=1)\n                ni = topi.view(1,-1)\n                #no teacher forcing during testing,keeping the predicted word as input to next step\n                decoder_input = ni\n                dec_h_hidden = dec_outputs[0]\n                dec_c_hidden = dec_outputs[1]\n\n                loss +=criterion(pred,target_batch[i])\n\n            batch_loss = loss.item() / target_batch.shape[0]\n            losses += batch_loss\n            \n    return losses / len(test_batches)","metadata":{"id":"XgJEmjyovtdA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#return translation of a sentence\ndef evaluate(encoder, decoder, sentence, cutoff_length):\n    with torch.no_grad():\n        # Encode the input as state vectors.\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_tensor = input_tensor.view(-1,1)\n        enc_h_hidden, enc_c_hidden = encoder.initHidden(1)\n        enc_hiddens, enc_outputs = encoder(input_tensor, enc_h_hidden, enc_c_hidden)\n        # Generate empty target sequence of length 1, Populate the first character of target sequence with the start character\n        decoder_input = Variable(torch.LongTensor(1,1).fill_(output_lang.word2index.get(\"SOS\")).cuda())\n        dec_h_hidden = enc_outputs[0]\n        dec_c_hidden = enc_outputs[1]\n\n        decoded_words = []\n\n        for di in range(cutoff_length):\n            pred, dec_outputs = decoder(decoder_input, dec_h_hidden, dec_c_hidden, enc_hiddens)\n            #Sample a token\n            topv, topi = pred.topk(1,dim=1)\n            ni = topi.item()\n            #find stop character\n            if(ni == output_lang.word2index.get(\"EOS\")):\n                decoded_words.append(\"EOS\")\n                break\n            else:\n                decoded_words.append(output_lang.index2word[ni])\n            # Update the target sequence (of length 1)\n            decoder_input = Variable(torch.LongTensor(1,1).fill_(ni).cuda())\n            dec_h_hidden = dec_outputs[0]\n            dec_c_hidden = dec_outputs[1]\n\n        output_sentence = ' '.join(decoded_words[:-1])\n        return output_sentence","metadata":{"id":"fm1WOk40vtdA","trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\nfrom random import shuffle\nfrom torch.autograd import Variable","metadata":{"id":"2NrZ3T_EvtdB","trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def evaluate_randomly(encoder, decoder, pairs, n=1):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_sentence = evaluate(encoder, decoder, pair[0],cutoff_length=150)\n        print('<', output_sentence)\n        print('')","metadata":{"id":"s2L62FivvtdC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def timeSpent(s):\n    m = math.floor(s / 60)\n    h = math.floor(m / 60)\n    s -= m * 60\n    m -= h * 60\n    return '%dh %dm %ds' % (h, m, s)","metadata":{"id":"kUI_HnXjvtdD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_file = \"save3_weight512\"","metadata":{"id":"7PlU36YvvtdD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test(epochs, test_every, learning_rate, train_pairs, test_pairs, input_lang, output_lang, batch_size, test_batch_size, encoder, decoder,criterion):\n    #test_batches = batchify(test_pairs, test_batch_size)\n    #keep track of losses\n    train_plot_losses = []\n    val_plot_losses = []\n    start = time.time()\n    #Cycle through epochs\n    for i in range(1,epochs+1):\n        encoder.train()\n        decoder.train()\n        #Initialize Optimizer\n        encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n        decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n\n        batches = batchify(train_pairs, batch_size)\n        train_loss = train(batches, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        train_plot_losses.append(train_loss)\n\n        now = time.time()\n        print(\"Iteration: %s \\nLearning Rate: %s \\nTime: %s \\nTrain Loss: %s \\n\" % (i, learning_rate, timeSpent(now-start), train_loss))\n\n#         if(i % test_every == 0):\n#             test_loss = test(test_batches, encoder, decoder, criterion)\n#             val_plot_losses.append(test_loss)\n#             print(\"Test Loss: %s\" % (test_loss))\n#             evaluate_randomly(encoder, decoder, test_pairs,1)\n\n        torch.save(encoder.state_dict(), output_file+'_enc.pt')\n        torch.save(decoder.state_dict(), output_file+'_dec.pt')\n\n        history = {'train_loss' : train_plot_losses,\n               'val_loss': val_plot_losses,\n           }\n\n    return history","metadata":{"id":"ZgqYQEgCvtdE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hidden_size = 512\nencoder = EncoderRNN(input_lang.n_words, hidden_size, layers=3,dropout_p=0.1, bidirectional=True).to(device)\ndecoder = DecoderAttn(hidden_size, output_lang.n_words, layers=3,dropout_p=0.1, bidirectional=True).to(device)","metadata":{"id":"nyjNVx5fvtdE","trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"encoder","metadata":{"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"EncoderRNN(\n  (embed): Embedding(43447, 512)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (lstm): LSTM(512, 512, num_layers=3, dropout=0.1, bidirectional=True)\n  (fc): Linear(in_features=1024, out_features=512, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Specify loss function, ignore the padded \"SOS\" index so it does not contribute to loss.\n#criterion = nn.NLLLoss(ignore_index=0)\ncriterion = nn.CrossEntropyLoss(ignore_index=0)","metadata":{"id":"xBzA-QgEvtdF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pairs=[]\nhistory = train_test(epochs=12, test_every= 1,learning_rate= 0.001, train_pairs = tr_pairs, test_pairs = val_pairs, input_lang=input_lang, output_lang = output_lang, batch_size = 64, \n               test_batch_size = 64, encoder = encoder, decoder = decoder, criterion = criterion)","metadata":{"id":"l30XYMNEvtdF","outputId":"9fe070bb-b568-4435-ea99-72ada93dc96a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = []\ndef evaluate_Randomly(encoder, decoder, pairs1):\n  for i in range(len(pairs1)):\n    pair = pairs1[i]\n    output_sentence = evaluate(encoder, decoder,pair[0],cutoff_length=150)\n    output_sentence = output_sentence+\"\\n\"\n    pred.append(output_sentence)\n    f1.writelines(output_sentence)","metadata":{"id":"345cHWAnvtdG","trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"f1= open(\"answer.txt\",'w')","metadata":{"id":"6YinChQNvtdH","trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"evaluate_Randomly(encoder, decoder, pairst)","metadata":{"id":"DjMSR3DCvtdH","trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"f1.close()","metadata":{"id":"ZM2g_lupL5WG","trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#load the state from dictionary \nencoder.load_state_dict(torch.load(\"/kaggle/input/lstm1024/save3_weight512_enc.pt\"))\ndecoder.load_state_dict(torch.load(\"/kaggle/input/lstm1024/save3_weight512_dec.pt\"))","metadata":{"scrolled":true,"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"#set to inference mode\nencoder.eval().to(device)\ndecoder.eval().to(device)","metadata":{"scrolled":true,"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"DecoderAttn(\n  (embed): Embedding(29399, 512)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (score_learner): Linear(in_features=1024, out_features=1024, bias=True)\n  (lstm): LSTM(512, 512, num_layers=3, dropout=0.1, bidirectional=True)\n  (context_combiner): Linear(in_features=2048, out_features=512, bias=True)\n  (tanh): Tanh()\n  (output): Linear(in_features=512, out_features=29399, bias=True)\n  (soft): Softmax(dim=1)\n  (log_soft): LogSoftmax(dim=1)\n)"},"metadata":{}}]},{"cell_type":"code","source":"#len(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\n#PLot the train and validation loss \nplt.figure()\nfig, ax = plt.subplots()\nplt.plot(history['train_loss'], label = 'train loss')\nplt.plot(history['val_loss'], label = 'val loss')\nplt.title('Loss vs Training steps')\nplt.xlabel('Training epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}